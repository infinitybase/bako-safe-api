"use strict";
var __defProp = Object.defineProperty;
var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
var __getOwnPropNames = Object.getOwnPropertyNames;
var __hasOwnProp = Object.prototype.hasOwnProperty;
var __defNormalProp = (obj, key, value) => key in obj ? __defProp(obj, key, { enumerable: true, configurable: true, writable: true, value }) : obj[key] = value;
var __export = (target, all) => {
  for (var name in all)
    __defProp(target, name, { get: all[name], enumerable: true });
};
var __copyProps = (to, from, except, desc) => {
  if (from && typeof from === "object" || typeof from === "function") {
    for (let key of __getOwnPropNames(from))
      if (!__hasOwnProp.call(to, key) && key !== except)
        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });
  }
  return to;
};
var __toCommonJS = (mod) => __copyProps(__defProp({}, "__esModule", { value: true }), mod);
var __publicField = (obj, key, value) => {
  __defNormalProp(obj, typeof key !== "symbol" ? key + "" : key, value);
  return value;
};
var __accessCheck = (obj, member, msg) => {
  if (!member.has(obj))
    throw TypeError("Cannot " + msg);
};
var __privateAdd = (obj, member, value) => {
  if (member.has(obj))
    throw TypeError("Cannot add the same private member more than once");
  member instanceof WeakSet ? member.add(obj) : member.set(obj, value);
};
var __privateMethod = (obj, member, method) => {
  __accessCheck(obj, member, "access private method");
  return method;
};

// src/index.ts
var src_exports = {};
__export(src_exports, {
  ASSET_ID_LEN: () => ASSET_ID_LEN,
  ArrayCoder: () => ArrayCoder,
  B256Coder: () => B256Coder,
  B512Coder: () => B512Coder,
  BooleanCoder: () => BooleanCoder,
  CONTRACT_ID_LEN: () => CONTRACT_ID_LEN,
  Coder: () => Coder,
  EnumCoder: () => EnumCoder,
  INPUT_COIN_FIXED_SIZE: () => INPUT_COIN_FIXED_SIZE,
  Interface: () => Interface,
  NumberCoder: () => NumberCoder,
  SCRIPT_FIXED_SIZE: () => SCRIPT_FIXED_SIZE,
  StringCoder: () => StringCoder,
  StructCoder: () => StructCoder,
  TupleCoder: () => TupleCoder,
  U64Coder: () => U64Coder,
  VecCoder: () => VecCoder,
  WORD_SIZE: () => WORD_SIZE,
  calculateVmTxMemory: () => calculateVmTxMemory
});
module.exports = __toCommonJS(src_exports);

// src/coders/abstract-coder.ts
var Coder = class {
  name;
  type;
  encodedLength;
  constructor(name, type, encodedLength) {
    this.name = name;
    this.type = type;
    this.encodedLength = encodedLength;
  }
};

// src/coders/v0/array.ts
var import_errors3 = require("@fuel-ts/errors");

// src/constants.ts
var OPTION_CODER_TYPE = "enum Option";
var VEC_CODER_TYPE = "struct Vec";
var BYTES_CODER_TYPE = "struct Bytes";
var STD_STRING_CODER_TYPE = "struct String";
var stringRegEx = /str\[(?<length>[0-9]+)\]/;
var arrayRegEx = /\[(?<item>[\w\s\\[\]]+);\s*(?<length>[0-9]+)\]/;
var structRegEx = /^struct (?<name>\w+)$/;
var enumRegEx = /^enum (?<name>\w+)$/;
var tupleRegEx = /^\((?<items>.*)\)$/;
var genericRegEx = /^generic (?<name>\w+)$/;
var WORD_SIZE = 8;
var BYTES_32 = 32;
var ASSET_ID_LEN = BYTES_32;
var CONTRACT_ID_LEN = BYTES_32;
var ADDRESS_LEN = BYTES_32;
var NONCE_LEN = BYTES_32;
var TX_LEN = WORD_SIZE * 4;
var TX_POINTER_LEN = WORD_SIZE * 2;
var MAX_BYTES = 2 ** 32 - 1;
var calculateVmTxMemory = ({ maxInputs }) => BYTES_32 + // Tx ID
WORD_SIZE + // Tx size
// Asset ID/Balance coin input pairs
maxInputs * (ASSET_ID_LEN + WORD_SIZE);
var SCRIPT_FIXED_SIZE = WORD_SIZE + // Identifier
WORD_SIZE + // Gas limit
WORD_SIZE + // Script size
WORD_SIZE + // Script data size
WORD_SIZE + // Policies
WORD_SIZE + // Inputs size
WORD_SIZE + // Outputs size
WORD_SIZE + // Witnesses size
BYTES_32;
var INPUT_COIN_FIXED_SIZE = WORD_SIZE + // Identifier
TX_LEN + // Utxo Length
WORD_SIZE + // Output Index
ADDRESS_LEN + // Owner
WORD_SIZE + // Amount
ASSET_ID_LEN + // Asset id
TX_POINTER_LEN + // TxPointer
WORD_SIZE + // Witnesses index
WORD_SIZE + // Maturity
WORD_SIZE + // Predicate size
WORD_SIZE + // Predicate data size
WORD_SIZE;
var INPUT_MESSAGE_FIXED_SIZE = WORD_SIZE + // Identifier
ADDRESS_LEN + // Sender
ADDRESS_LEN + // Recipient
WORD_SIZE + // Amount
NONCE_LEN + // Nonce
WORD_SIZE + // witness_index
WORD_SIZE + // Data size
WORD_SIZE + // Predicate size
WORD_SIZE + // Predicate data size
WORD_SIZE;

// src/utilities.ts
var import_errors2 = require("@fuel-ts/errors");
var import_utils = require("@fuel-ts/utils");
var import_ethers = require("ethers");

// src/coders/v0/u64.ts
var import_errors = require("@fuel-ts/errors");
var import_math = require("@fuel-ts/math");
var U64Coder = class extends Coder {
  constructor() {
    super("u64", "u64", WORD_SIZE);
  }
  encode(value) {
    let bytes;
    try {
      bytes = (0, import_math.toBytes)(value, WORD_SIZE);
    } catch (error) {
      throw new import_errors.FuelError(import_errors.ErrorCode.ENCODE_ERROR, `Invalid ${this.type}.`);
    }
    return bytes;
  }
  decode(data, offset) {
    if (data.length < this.encodedLength) {
      throw new import_errors.FuelError(import_errors.ErrorCode.DECODE_ERROR, `Invalid ${this.type} data size.`);
    }
    let bytes = data.slice(offset, offset + WORD_SIZE);
    bytes = bytes.slice(0, WORD_SIZE);
    if (bytes.length !== this.encodedLength) {
      throw new import_errors.FuelError(import_errors.ErrorCode.DECODE_ERROR, `Invalid ${this.type} byte data size.`);
    }
    return [(0, import_math.bn)(bytes), offset + WORD_SIZE];
  }
};

// src/utilities.ts
var VEC_PROPERTY_SPACE = 3;
var BASE_VECTOR_OFFSET = VEC_PROPERTY_SPACE * WORD_SIZE;
var RAW_SLICE_PROPERTY_SPACE = 2;
var BASE_RAW_SLICE_OFFSET = RAW_SLICE_PROPERTY_SPACE * WORD_SIZE;
function concatWithDynamicData(items) {
  const topLevelData = {};
  let totalIndex = 0;
  const objects = items.map((item) => {
    const dynamicData = item.dynamicData;
    if (dynamicData) {
      Object.entries(dynamicData).forEach(([pointerIndex, vData]) => {
        topLevelData[parseInt(pointerIndex, 10) + totalIndex] = vData;
      });
    }
    const byteArray = (0, import_ethers.getBytesCopy)(item);
    totalIndex += byteArray.byteLength / WORD_SIZE;
    return byteArray;
  });
  const length = objects.reduce((accum, item) => accum + item.length, 0);
  const result = new Uint8Array(length);
  objects.reduce((offset, object) => {
    result.set(object, offset);
    return offset + object.length;
  }, 0);
  if (Object.keys(topLevelData).length) {
    result.dynamicData = topLevelData;
  }
  return result;
}
function unpackDynamicData(results, baseOffset, dataOffset) {
  if (!results.dynamicData) {
    return (0, import_utils.concat)([results]);
  }
  let cumulativeDynamicByteLength = 0;
  let updatedResults = results;
  Object.entries(results.dynamicData).forEach(([pointerIndex, vData]) => {
    const pointerOffset = parseInt(pointerIndex, 10) * WORD_SIZE;
    const adjustedValue = new U64Coder().encode(
      dataOffset + baseOffset + cumulativeDynamicByteLength
    );
    updatedResults.set(adjustedValue, pointerOffset);
    const dataToAppend = vData.dynamicData ? (
      // unpack child dynamic data
      unpackDynamicData(
        vData,
        baseOffset,
        dataOffset + vData.byteLength + cumulativeDynamicByteLength
      )
    ) : vData;
    updatedResults = (0, import_utils.concat)([updatedResults, dataToAppend]);
    cumulativeDynamicByteLength += dataToAppend.byteLength;
  });
  return updatedResults;
}
var chunkByLength = (data, length = WORD_SIZE) => {
  const chunks = [];
  let offset = 0;
  let chunk = data.slice(offset, offset + length);
  while (chunk.length) {
    chunks.push(chunk);
    offset += length;
    chunk = data.slice(offset, offset + length);
  }
  return chunks;
};
var isPointerType = (type) => {
  switch (type) {
    case "u8":
    case "u16":
    case "u32":
    case "u64":
    case "bool": {
      return false;
    }
    default: {
      return true;
    }
  }
};
var isHeapType = (type) => type === VEC_CODER_TYPE || type === BYTES_CODER_TYPE || type === STD_STRING_CODER_TYPE;
function findOrThrow(arr, predicate, throwFn = () => {
  throw new import_errors2.FuelError(import_errors2.ErrorCode.ELEMENT_NOT_FOUND, "Element not found in the array.");
}) {
  const found = arr.find(predicate);
  if (found === void 0) {
    throwFn();
  }
  return found;
}
var isMultipleOfWordSize = (length) => length % WORD_SIZE === 0;
var getWordSizePadding = (length) => WORD_SIZE - length % WORD_SIZE;
var rightPadToWordSize = (encoded) => {
  if (isMultipleOfWordSize(encoded.length)) {
    return encoded;
  }
  const padding = new Uint8Array(WORD_SIZE - encoded.length % WORD_SIZE);
  return (0, import_utils.concatBytes)([encoded, padding]);
};

// src/coders/v0/array.ts
var ArrayCoder = class extends Coder {
  coder;
  length;
  constructor(coder, length) {
    super("array", `[${coder.type}; ${length}]`, length * coder.encodedLength);
    this.coder = coder;
    this.length = length;
  }
  encode(value) {
    if (!Array.isArray(value)) {
      throw new import_errors3.FuelError(import_errors3.ErrorCode.ENCODE_ERROR, `Expected array value.`);
    }
    if (this.length !== value.length) {
      throw new import_errors3.FuelError(import_errors3.ErrorCode.ENCODE_ERROR, `Types/values length mismatch.`);
    }
    return concatWithDynamicData(Array.from(value).map((v) => this.coder.encode(v)));
  }
  decode(data, offset) {
    if (data.length < this.encodedLength || data.length > MAX_BYTES) {
      throw new import_errors3.FuelError(import_errors3.ErrorCode.DECODE_ERROR, `Invalid array data size.`);
    }
    let newOffset = offset;
    const decodedValue = Array(this.length).fill(0).map(() => {
      let decoded;
      [decoded, newOffset] = this.coder.decode(data, newOffset);
      return decoded;
    });
    return [decodedValue, newOffset];
  }
};

// src/coders/v0/b256.ts
var import_errors4 = require("@fuel-ts/errors");
var import_math2 = require("@fuel-ts/math");
var import_ethers2 = require("ethers");
var B256Coder = class extends Coder {
  constructor() {
    super("b256", "b256", WORD_SIZE * 4);
  }
  encode(value) {
    let encodedValue;
    try {
      encodedValue = (0, import_ethers2.getBytesCopy)(value);
    } catch (error) {
      throw new import_errors4.FuelError(import_errors4.ErrorCode.ENCODE_ERROR, `Invalid ${this.type}.`);
    }
    if (encodedValue.length !== this.encodedLength) {
      throw new import_errors4.FuelError(import_errors4.ErrorCode.ENCODE_ERROR, `Invalid ${this.type}.`);
    }
    return encodedValue;
  }
  decode(data, offset) {
    if (data.length < this.encodedLength) {
      throw new import_errors4.FuelError(import_errors4.ErrorCode.DECODE_ERROR, `Invalid b256 data size.`);
    }
    let bytes = data.slice(offset, offset + this.encodedLength);
    const decoded = (0, import_math2.bn)(bytes);
    if (decoded.isZero()) {
      bytes = new Uint8Array(32);
    }
    if (bytes.length !== this.encodedLength) {
      throw new import_errors4.FuelError(import_errors4.ErrorCode.DECODE_ERROR, `Invalid b256 byte data size.`);
    }
    return [(0, import_math2.toHex)(bytes, 32), offset + 32];
  }
};

// src/coders/v0/b512.ts
var import_errors5 = require("@fuel-ts/errors");
var import_math3 = require("@fuel-ts/math");
var import_ethers3 = require("ethers");
var B512Coder = class extends Coder {
  constructor() {
    super("b512", "struct B512", WORD_SIZE * 8);
  }
  encode(value) {
    let encodedValue;
    try {
      encodedValue = (0, import_ethers3.getBytesCopy)(value);
    } catch (error) {
      throw new import_errors5.FuelError(import_errors5.ErrorCode.ENCODE_ERROR, `Invalid ${this.type}.`);
    }
    if (encodedValue.length !== this.encodedLength) {
      throw new import_errors5.FuelError(import_errors5.ErrorCode.ENCODE_ERROR, `Invalid ${this.type}.`);
    }
    return encodedValue;
  }
  decode(data, offset) {
    if (data.length < this.encodedLength) {
      throw new import_errors5.FuelError(import_errors5.ErrorCode.DECODE_ERROR, `Invalid b512 data size.`);
    }
    let bytes = data.slice(offset, offset + this.encodedLength);
    const decoded = (0, import_math3.bn)(bytes);
    if (decoded.isZero()) {
      bytes = new Uint8Array(64);
    }
    if (bytes.length !== this.encodedLength) {
      throw new import_errors5.FuelError(import_errors5.ErrorCode.DECODE_ERROR, `Invalid b512 byte data size.`);
    }
    return [(0, import_math3.toHex)(bytes, this.encodedLength), offset + this.encodedLength];
  }
};

// src/coders/v0/boolean.ts
var import_errors6 = require("@fuel-ts/errors");
var import_math4 = require("@fuel-ts/math");
var BooleanCoder = class extends Coder {
  paddingLength;
  options;
  constructor(options = {
    isSmallBytes: false,
    isRightPadded: false
  }) {
    const paddingLength = options.isSmallBytes ? 1 : 8;
    super("boolean", "boolean", paddingLength);
    this.paddingLength = paddingLength;
    this.options = options;
  }
  encode(value) {
    const isTrueBool = value === true || value === false;
    if (!isTrueBool) {
      throw new import_errors6.FuelError(import_errors6.ErrorCode.ENCODE_ERROR, `Invalid boolean value.`);
    }
    const output = (0, import_math4.toBytes)(value ? 1 : 0, this.paddingLength);
    if (this.options.isRightPadded) {
      return output.reverse();
    }
    return output;
  }
  decode(data, offset) {
    if (data.length < this.paddingLength) {
      throw new import_errors6.FuelError(import_errors6.ErrorCode.DECODE_ERROR, `Invalid boolean data size.`);
    }
    let bytes;
    if (this.options.isRightPadded) {
      bytes = data.slice(offset, offset + 1);
    } else {
      bytes = data.slice(offset, offset + this.paddingLength);
    }
    const decodedValue = (0, import_math4.bn)(bytes);
    if (decodedValue.isZero()) {
      return [false, offset + this.paddingLength];
    }
    if (!decodedValue.eq((0, import_math4.bn)(1))) {
      throw new import_errors6.FuelError(import_errors6.ErrorCode.DECODE_ERROR, `Invalid boolean value.`);
    }
    return [true, offset + this.paddingLength];
  }
};

// src/coders/v0/enum.ts
var import_errors7 = require("@fuel-ts/errors");
var import_math5 = require("@fuel-ts/math");
var import_utils2 = require("@fuel-ts/utils");
var isFullyNativeEnum = (enumCoders) => Object.values(enumCoders).every(
  // @ts-expect-error complicated types
  ({ type, coders }) => type === "()" && JSON.stringify(coders) === JSON.stringify([])
);
var EnumCoder = class extends Coder {
  name;
  coders;
  #caseIndexCoder;
  #encodedValueSize;
  constructor(name, coders) {
    const caseIndexCoder = new U64Coder();
    const encodedValueSize = Object.values(coders).reduce(
      (max, coder) => Math.max(max, coder.encodedLength),
      0
    );
    super("enum", `enum ${name}`, caseIndexCoder.encodedLength + encodedValueSize);
    this.name = name;
    this.coders = coders;
    this.#caseIndexCoder = caseIndexCoder;
    this.#encodedValueSize = encodedValueSize;
  }
  #encodeNativeEnum(value) {
    const valueCoder = this.coders[value];
    const encodedValue = valueCoder.encode([]);
    const caseIndex = Object.keys(this.coders).indexOf(value);
    const padding = new Uint8Array(this.#encodedValueSize - valueCoder.encodedLength);
    return (0, import_utils2.concat)([this.#caseIndexCoder.encode(caseIndex), padding, encodedValue]);
  }
  encode(value) {
    if (typeof value === "string" && this.coders[value]) {
      return this.#encodeNativeEnum(value);
    }
    const [caseKey, ...empty] = Object.keys(value);
    if (!caseKey) {
      throw new import_errors7.FuelError(import_errors7.ErrorCode.INVALID_DECODE_VALUE, "A field for the case must be provided.");
    }
    if (empty.length !== 0) {
      throw new import_errors7.FuelError(import_errors7.ErrorCode.INVALID_DECODE_VALUE, "Only one field must be provided.");
    }
    const valueCoder = this.coders[caseKey];
    const caseIndex = Object.keys(this.coders).indexOf(caseKey);
    const encodedValue = valueCoder.encode(value[caseKey]);
    const padding = new Uint8Array(this.#encodedValueSize - valueCoder.encodedLength);
    return concatWithDynamicData([this.#caseIndexCoder.encode(caseIndex), padding, encodedValue]);
  }
  #decodeNativeEnum(caseKey, newOffset) {
    return [caseKey, newOffset];
  }
  decode(data, offset) {
    if (data.length < this.#encodedValueSize) {
      throw new import_errors7.FuelError(import_errors7.ErrorCode.DECODE_ERROR, `Invalid enum data size.`);
    }
    let newOffset = offset;
    let decoded;
    [decoded, newOffset] = new U64Coder().decode(data, newOffset);
    const caseIndex = (0, import_math5.toNumber)(decoded);
    const caseKey = Object.keys(this.coders)[caseIndex];
    if (!caseKey) {
      throw new import_errors7.FuelError(
        import_errors7.ErrorCode.INVALID_DECODE_VALUE,
        `Invalid caseIndex "${caseIndex}". Valid cases: ${Object.keys(this.coders)}.`
      );
    }
    const valueCoder = this.coders[caseKey];
    const padding = this.#encodedValueSize - valueCoder.encodedLength;
    newOffset += padding;
    [decoded, newOffset] = valueCoder.decode(data, newOffset);
    if (isFullyNativeEnum(this.coders)) {
      return this.#decodeNativeEnum(caseKey, newOffset);
    }
    return [{ [caseKey]: decoded }, newOffset];
  }
};

// src/coders/v0/number.ts
var import_errors8 = require("@fuel-ts/errors");
var import_math6 = require("@fuel-ts/math");
var NumberCoder = class extends Coder {
  // This is to align the bits to the total bytes
  // See https://github.com/FuelLabs/fuel-specs/blob/master/specs/protocol/abi.md#unsigned-integers
  length;
  paddingLength;
  baseType;
  options;
  constructor(baseType, options = {
    isSmallBytes: false,
    isRightPadded: false
  }) {
    const paddingLength = options.isSmallBytes && baseType === "u8" ? 1 : 8;
    super("number", baseType, paddingLength);
    this.baseType = baseType;
    switch (baseType) {
      case "u8":
        this.length = 1;
        break;
      case "u16":
        this.length = 2;
        break;
      case "u32":
      default:
        this.length = 4;
        break;
    }
    this.paddingLength = paddingLength;
    this.options = options;
  }
  encode(value) {
    let bytes;
    try {
      bytes = (0, import_math6.toBytes)(value);
    } catch (error) {
      throw new import_errors8.FuelError(import_errors8.ErrorCode.ENCODE_ERROR, `Invalid ${this.baseType}.`);
    }
    if (bytes.length > this.length) {
      throw new import_errors8.FuelError(import_errors8.ErrorCode.ENCODE_ERROR, `Invalid ${this.baseType}, too many bytes.`);
    }
    const output = (0, import_math6.toBytes)(bytes, this.paddingLength);
    if (this.baseType !== "u8") {
      return output;
    }
    return this.options.isRightPadded ? output.reverse() : output;
  }
  decodeU8(data, offset) {
    let bytes;
    if (this.options.isRightPadded) {
      bytes = data.slice(offset, offset + 1);
    } else {
      bytes = data.slice(offset, offset + this.paddingLength);
      bytes = bytes.slice(this.paddingLength - this.length, this.paddingLength);
    }
    return [(0, import_math6.toNumber)(bytes), offset + this.paddingLength];
  }
  decode(data, offset) {
    if (data.length < this.paddingLength) {
      throw new import_errors8.FuelError(import_errors8.ErrorCode.DECODE_ERROR, `Invalid number data size.`);
    }
    if (this.baseType === "u8") {
      return this.decodeU8(data, offset);
    }
    let bytes = data.slice(offset, offset + this.paddingLength);
    bytes = bytes.slice(8 - this.length, 8);
    if (bytes.length !== this.paddingLength - (this.paddingLength - this.length)) {
      throw new import_errors8.FuelError(import_errors8.ErrorCode.DECODE_ERROR, `Invalid number byte data size.`);
    }
    return [(0, import_math6.toNumber)(bytes), offset + 8];
  }
};

// src/coders/v0/string.ts
var import_errors9 = require("@fuel-ts/errors");
var import_utils3 = require("@fuel-ts/utils");
var import_ethers4 = require("ethers");
var StringCoder = class extends Coder {
  length;
  #paddingLength;
  constructor(length) {
    let paddingLength = (8 - length) % 8;
    paddingLength = paddingLength < 0 ? paddingLength + 8 : paddingLength;
    super("string", `str[${length}]`, length + paddingLength);
    this.length = length;
    this.#paddingLength = paddingLength;
  }
  encode(value) {
    if (this.length !== value.length) {
      throw new import_errors9.FuelError(import_errors9.ErrorCode.ENCODE_ERROR, `Value length mismatch during encode.`);
    }
    const encoded = (0, import_ethers4.toUtf8Bytes)(value);
    const padding = new Uint8Array(this.#paddingLength);
    return (0, import_utils3.concat)([encoded, padding]);
  }
  decode(data, offset) {
    if (data.length < this.encodedLength) {
      throw new import_errors9.FuelError(import_errors9.ErrorCode.DECODE_ERROR, `Invalid string data size.`);
    }
    const bytes = data.slice(offset, offset + this.length);
    if (bytes.length !== this.length) {
      throw new import_errors9.FuelError(import_errors9.ErrorCode.DECODE_ERROR, `Invalid string byte data size.`);
    }
    const value = (0, import_ethers4.toUtf8String)(bytes);
    const padding = this.#paddingLength;
    return [value, offset + this.length + padding];
  }
};

// src/coders/v0/struct.ts
var import_errors11 = require("@fuel-ts/errors");

// src/coders/v0/option.ts
var import_errors10 = require("@fuel-ts/errors");
var OptionCoder = class extends EnumCoder {
  encode(value) {
    const result = super.encode(this.toSwayOption(value));
    return result;
  }
  toSwayOption(input) {
    if (input !== void 0) {
      return { Some: input };
    }
    return { None: [] };
  }
  decode(data, offset) {
    if (data.length < this.encodedLength - 1) {
      throw new import_errors10.FuelError(import_errors10.ErrorCode.DECODE_ERROR, `Invalid option data size.`);
    }
    const [decoded, newOffset] = super.decode(data, offset);
    return [this.toOption(decoded), newOffset];
  }
  toOption(output) {
    if (output && "Some" in output) {
      return output.Some;
    }
    return void 0;
  }
};

// src/coders/v0/struct.ts
var StructCoder = class extends Coder {
  name;
  coders;
  constructor(name, coders) {
    const encodedLength = Object.values(coders).reduce(
      (acc, coder) => acc + coder.encodedLength,
      0
    );
    super("struct", `struct ${name}`, encodedLength);
    this.name = name;
    this.coders = coders;
  }
  encode(value) {
    const encodedFields = Object.keys(this.coders).map((fieldName) => {
      const fieldCoder = this.coders[fieldName];
      const fieldValue = value[fieldName];
      if (!(fieldCoder instanceof OptionCoder) && fieldValue == null) {
        throw new import_errors11.FuelError(
          import_errors11.ErrorCode.ENCODE_ERROR,
          `Invalid ${this.type}. Field "${fieldName}" not present.`
        );
      }
      const encoded = fieldCoder.encode(fieldValue);
      if (!isMultipleOfWordSize(encoded.length)) {
        return rightPadToWordSize(encoded);
      }
      return encoded;
    });
    return concatWithDynamicData([concatWithDynamicData(encodedFields)]);
  }
  decode(data, offset) {
    if (data.length < this.encodedLength) {
      throw new import_errors11.FuelError(import_errors11.ErrorCode.DECODE_ERROR, `Invalid struct data size.`);
    }
    let newOffset = offset;
    const decodedValue = Object.keys(this.coders).reduce((obj, fieldName) => {
      const fieldCoder = this.coders[fieldName];
      let decoded;
      [decoded, newOffset] = fieldCoder.decode(data, newOffset);
      if (!isMultipleOfWordSize(newOffset)) {
        newOffset += getWordSizePadding(newOffset);
      }
      obj[fieldName] = decoded;
      return obj;
    }, {});
    return [decodedValue, newOffset];
  }
};

// src/coders/v0/tuple.ts
var import_errors12 = require("@fuel-ts/errors");
var TupleCoder = class extends Coder {
  coders;
  constructor(coders) {
    const encodedLength = coders.reduce((acc, coder) => acc + coder.encodedLength, 0);
    super("tuple", `(${coders.map((coder) => coder.type).join(", ")})`, encodedLength);
    this.coders = coders;
  }
  encode(value) {
    if (this.coders.length !== value.length) {
      throw new import_errors12.FuelError(import_errors12.ErrorCode.ENCODE_ERROR, `Types/values length mismatch.`);
    }
    return concatWithDynamicData(
      this.coders.map((coder, i) => {
        const encoded = coder.encode(value[i]);
        if (!isMultipleOfWordSize(encoded.length)) {
          return rightPadToWordSize(encoded);
        }
        return encoded;
      })
    );
  }
  decode(data, offset) {
    if (data.length < this.encodedLength) {
      throw new import_errors12.FuelError(import_errors12.ErrorCode.DECODE_ERROR, `Invalid tuple data size.`);
    }
    let newOffset = offset;
    const decodedValue = this.coders.map((coder) => {
      let decoded;
      [decoded, newOffset] = coder.decode(data, newOffset);
      if (!isMultipleOfWordSize(newOffset)) {
        newOffset += getWordSizePadding(newOffset);
      }
      return decoded;
    });
    return [decodedValue, newOffset];
  }
};

// src/coders/v0/vec.ts
var import_errors13 = require("@fuel-ts/errors");
var import_math7 = require("@fuel-ts/math");
var VecCoder = class extends Coder {
  coder;
  constructor(coder) {
    super("struct", `struct Vec`, coder.encodedLength + BASE_VECTOR_OFFSET);
    this.coder = coder;
  }
  encode(value) {
    if (!Array.isArray(value)) {
      throw new import_errors13.FuelError(import_errors13.ErrorCode.ENCODE_ERROR, `Expected array value.`);
    }
    const parts = [];
    const pointer = new U64Coder().encode(BASE_VECTOR_OFFSET);
    pointer.dynamicData = {
      0: concatWithDynamicData(Array.from(value).map((v) => this.coder.encode(v)))
    };
    parts.push(pointer);
    parts.push(new U64Coder().encode(value.length));
    parts.push(new U64Coder().encode(value.length));
    return concatWithDynamicData(parts);
  }
  decode(data, offset) {
    if (data.length < BASE_VECTOR_OFFSET || data.length > MAX_BYTES) {
      throw new import_errors13.FuelError(import_errors13.ErrorCode.DECODE_ERROR, `Invalid vec data size.`);
    }
    const len = data.slice(16, 24);
    const encodedLength = (0, import_math7.bn)(new U64Coder().decode(len, 0)[0]).toNumber();
    const vectorRawDataLength = encodedLength * this.coder.encodedLength;
    const vectorRawData = data.slice(BASE_VECTOR_OFFSET, BASE_VECTOR_OFFSET + vectorRawDataLength);
    if (vectorRawData.length !== vectorRawDataLength) {
      throw new import_errors13.FuelError(import_errors13.ErrorCode.DECODE_ERROR, `Invalid vec byte data size.`);
    }
    return [
      chunkByLength(vectorRawData, this.coder.encodedLength).map(
        (chunk) => this.coder.decode(chunk, 0)[0]
      ),
      offset + BASE_VECTOR_OFFSET
    ];
  }
};

// src/interface.ts
var import_errors30 = require("@fuel-ts/errors");
var import_ethers9 = require("ethers");

// src/abi-coder.ts
var import_errors28 = require("@fuel-ts/errors");

// src/coders/v0/byte.ts
var import_errors14 = require("@fuel-ts/errors");
var import_math8 = require("@fuel-ts/math");
var import_utils4 = require("@fuel-ts/utils");
var _getPaddedData, getPaddedData_fn;
var ByteCoder = class extends Coder {
  constructor() {
    super("struct", "struct Bytes", BASE_VECTOR_OFFSET);
    __privateAdd(this, _getPaddedData);
  }
  encode(value) {
    if (!Array.isArray(value)) {
      throw new import_errors14.FuelError(import_errors14.ErrorCode.ENCODE_ERROR, `Expected array value.`);
    }
    const parts = [];
    const pointer = new U64Coder().encode(BASE_VECTOR_OFFSET);
    const data = __privateMethod(this, _getPaddedData, getPaddedData_fn).call(this, value);
    pointer.dynamicData = {
      0: concatWithDynamicData([data])
    };
    parts.push(pointer);
    parts.push(new U64Coder().encode(data.byteLength));
    parts.push(new U64Coder().encode(value.length));
    return concatWithDynamicData(parts);
  }
  decode(data, offset) {
    if (data.length < BASE_VECTOR_OFFSET) {
      throw new import_errors14.FuelError(import_errors14.ErrorCode.DECODE_ERROR, `Invalid byte data size.`);
    }
    const len = data.slice(16, 24);
    const encodedLength = (0, import_math8.bn)(new U64Coder().decode(len, 0)[0]).toNumber();
    const byteData = data.slice(BASE_VECTOR_OFFSET, BASE_VECTOR_OFFSET + encodedLength);
    if (byteData.length !== encodedLength) {
      throw new import_errors14.FuelError(import_errors14.ErrorCode.DECODE_ERROR, `Invalid bytes byte data size.`);
    }
    return [byteData, offset + BASE_VECTOR_OFFSET];
  }
};
_getPaddedData = new WeakSet();
getPaddedData_fn = function(value) {
  const data = [Uint8Array.from(value)];
  const paddingLength = (WORD_SIZE - value.length % WORD_SIZE) % WORD_SIZE;
  if (paddingLength) {
    data.push(new Uint8Array(paddingLength));
  }
  return (0, import_utils4.concat)(data);
};
__publicField(ByteCoder, "memorySize", 1);

// src/coders/v0/raw-slice.ts
var import_errors15 = require("@fuel-ts/errors");
var RawSliceCoder = class extends Coder {
  constructor() {
    super("raw untyped slice", "raw untyped slice", BASE_RAW_SLICE_OFFSET);
  }
  encode(value) {
    if (!Array.isArray(value)) {
      throw new import_errors15.FuelError(import_errors15.ErrorCode.ENCODE_ERROR, `Expected array value.`);
    }
    const parts = [];
    const coder = new NumberCoder("u8", { isSmallBytes: true });
    const pointer = new U64Coder().encode(BASE_RAW_SLICE_OFFSET);
    pointer.dynamicData = {
      0: concatWithDynamicData(value.map((v) => coder.encode(v)))
    };
    parts.push(pointer);
    parts.push(new U64Coder().encode(value.length));
    return concatWithDynamicData(parts);
  }
  decode(data, offset) {
    const dataBytes = data.slice(offset);
    const internalCoder = new ArrayCoder(
      new NumberCoder("u8", { isSmallBytes: true }),
      dataBytes.length
    );
    const [decodedValue] = internalCoder.decode(dataBytes, 0);
    return [decodedValue, offset + dataBytes.length];
  }
};

// src/coders/v0/stdString.ts
var import_errors16 = require("@fuel-ts/errors");
var import_math9 = require("@fuel-ts/math");
var import_utils5 = require("@fuel-ts/utils");
var import_ethers5 = require("ethers");
var _getPaddedData2, getPaddedData_fn2;
var StdStringCoder = class extends Coder {
  constructor() {
    super("struct", "struct String", 1);
    __privateAdd(this, _getPaddedData2);
  }
  encode(value) {
    const parts = [];
    const pointer = new U64Coder().encode(BASE_VECTOR_OFFSET);
    const data = __privateMethod(this, _getPaddedData2, getPaddedData_fn2).call(this, value);
    pointer.dynamicData = {
      0: concatWithDynamicData([data])
    };
    parts.push(pointer);
    parts.push(new U64Coder().encode(data.byteLength));
    parts.push(new U64Coder().encode(value.length));
    return concatWithDynamicData(parts);
  }
  decode(data, offset) {
    if (data.length < this.encodedLength) {
      throw new import_errors16.FuelError(import_errors16.ErrorCode.DECODE_ERROR, `Invalid std string data size.`);
    }
    const len = data.slice(16, 24);
    const encodedLength = (0, import_math9.bn)(new U64Coder().decode(len, 0)[0]).toNumber();
    const byteData = data.slice(BASE_VECTOR_OFFSET, BASE_VECTOR_OFFSET + encodedLength);
    if (byteData.length !== encodedLength) {
      throw new import_errors16.FuelError(import_errors16.ErrorCode.DECODE_ERROR, `Invalid std string byte data size.`);
    }
    const value = (0, import_ethers5.toUtf8String)(byteData);
    return [value, offset + BASE_VECTOR_OFFSET];
  }
};
_getPaddedData2 = new WeakSet();
getPaddedData_fn2 = function(value) {
  const data = [(0, import_ethers5.toUtf8Bytes)(value)];
  const paddingLength = (WORD_SIZE - value.length % WORD_SIZE) % WORD_SIZE;
  if (paddingLength) {
    data.push(new Uint8Array(paddingLength));
  }
  return (0, import_utils5.concat)(data);
};
__publicField(StdStringCoder, "memorySize", 1);

// src/coders/v1/boolean.ts
var import_errors17 = require("@fuel-ts/errors");
var import_math10 = require("@fuel-ts/math");
var BooleanCoder2 = class extends Coder {
  constructor() {
    super("boolean", "boolean", 1);
  }
  encode(value) {
    const isTrueBool = value === true || value === false;
    if (!isTrueBool) {
      throw new import_errors17.FuelError(import_errors17.ErrorCode.ENCODE_ERROR, `Invalid boolean value.`);
    }
    return (0, import_math10.toBytes)(value ? 1 : 0, this.encodedLength);
  }
  decode(data, offset) {
    if (data.length < this.encodedLength) {
      throw new import_errors17.FuelError(import_errors17.ErrorCode.DECODE_ERROR, `Invalid boolean data size.`);
    }
    const bytes = (0, import_math10.bn)(data.slice(offset, offset + this.encodedLength));
    if (bytes.isZero()) {
      return [false, offset + this.encodedLength];
    }
    if (!bytes.eq((0, import_math10.bn)(1))) {
      throw new import_errors17.FuelError(import_errors17.ErrorCode.DECODE_ERROR, `Invalid boolean value.`);
    }
    return [true, offset + this.encodedLength];
  }
};

// src/coders/v1/byte.ts
var import_errors18 = require("@fuel-ts/errors");
var import_math11 = require("@fuel-ts/math");
var ByteCoder2 = class extends Coder {
  constructor() {
    super("struct", "struct Bytes", 1);
  }
  encode(_value) {
    throw new import_errors18.FuelError(import_errors18.ErrorCode.ENCODE_ERROR, `Bytes encode unsupported in v1`);
  }
  decode(data, offset) {
    if (data.length < WORD_SIZE) {
      throw new import_errors18.FuelError(import_errors18.ErrorCode.DECODE_ERROR, `Invalid byte data size.`);
    }
    const offsetAndLength = offset + WORD_SIZE;
    const lengthBytes = data.slice(offset, offsetAndLength);
    const length = (0, import_math11.bn)(new U64Coder().decode(lengthBytes, 0)[0]).toNumber();
    const dataLength = length * this.encodedLength;
    const dataBytes = data.slice(offsetAndLength, offsetAndLength + dataLength);
    if (dataBytes.length !== length) {
      throw new import_errors18.FuelError(import_errors18.ErrorCode.DECODE_ERROR, `Invalid bytes byte data size.`);
    }
    return [dataBytes, offset + dataLength];
  }
};
__publicField(ByteCoder2, "memorySize", 1);

// src/coders/v1/enum.ts
var import_errors19 = require("@fuel-ts/errors");
var import_math12 = require("@fuel-ts/math");
var isFullyNativeEnum2 = (enumCoders) => Object.values(enumCoders).every(
  // @ts-expect-error complicated types
  ({ type, coders }) => type === "()" && JSON.stringify(coders) === JSON.stringify([])
);
var EnumCoder2 = class extends Coder {
  name;
  coders;
  #caseIndexCoder;
  #encodedValueSize;
  constructor(name, coders) {
    const caseIndexCoder = new U64Coder();
    const encodedValueSize = Object.values(coders).reduce(
      (max, coder) => Math.max(max, coder.encodedLength),
      0
    );
    super("enum", `enum ${name}`, caseIndexCoder.encodedLength + encodedValueSize);
    this.name = name;
    this.coders = coders;
    this.#caseIndexCoder = caseIndexCoder;
    this.#encodedValueSize = encodedValueSize;
  }
  encode(_value) {
    throw new import_errors19.FuelError(import_errors19.ErrorCode.ENCODE_ERROR, `Enum encode unsupported in v1`);
  }
  #decodeNativeEnum(caseKey, newOffset) {
    return [caseKey, newOffset];
  }
  decode(data, offset) {
    if (data.length < this.#encodedValueSize) {
      throw new import_errors19.FuelError(import_errors19.ErrorCode.DECODE_ERROR, `Invalid enum data size.`);
    }
    const caseBytes = new U64Coder().decode(data, offset)[0];
    const caseIndex = (0, import_math12.toNumber)(caseBytes);
    const caseKey = Object.keys(this.coders)[caseIndex];
    if (!caseKey) {
      throw new import_errors19.FuelError(
        import_errors19.ErrorCode.INVALID_DECODE_VALUE,
        `Invalid caseIndex "${caseIndex}". Valid cases: ${Object.keys(this.coders)}.`
      );
    }
    const valueCoder = this.coders[caseKey];
    const offsetAndCase = offset + WORD_SIZE;
    const [decoded, newOffset] = valueCoder.decode(data, offsetAndCase);
    if (isFullyNativeEnum2(this.coders)) {
      return this.#decodeNativeEnum(caseKey, newOffset);
    }
    return [{ [caseKey]: decoded }, newOffset];
  }
};

// src/coders/v1/number.ts
var import_errors20 = require("@fuel-ts/errors");
var import_math13 = require("@fuel-ts/math");
var getLength = (baseType) => {
  switch (baseType) {
    case "u8":
      return 1;
    case "u16":
      return 2;
    case "u32":
      return 4;
    default:
      throw new import_errors20.FuelError(import_errors20.ErrorCode.TYPE_NOT_SUPPORTED, `Invalid number type: ${baseType}`);
  }
};
var NumberCoder2 = class extends Coder {
  length;
  baseType;
  constructor(baseType) {
    const length = getLength(baseType);
    super("number", baseType, length);
    this.baseType = baseType;
    this.length = length;
  }
  encode(value) {
    let bytes;
    try {
      bytes = (0, import_math13.toBytes)(value);
    } catch (error) {
      throw new import_errors20.FuelError(import_errors20.ErrorCode.ENCODE_ERROR, `Invalid ${this.baseType}.`);
    }
    if (bytes.length > this.length) {
      throw new import_errors20.FuelError(import_errors20.ErrorCode.ENCODE_ERROR, `Invalid ${this.baseType}, too many bytes.`);
    }
    return (0, import_math13.toBytes)(bytes, this.length);
  }
  decode(data, offset) {
    if (data.length < this.encodedLength) {
      throw new import_errors20.FuelError(import_errors20.ErrorCode.DECODE_ERROR, `Invalid number data size.`);
    }
    const bytes = data.slice(offset, offset + this.length);
    if (bytes.length !== this.encodedLength) {
      throw new import_errors20.FuelError(import_errors20.ErrorCode.DECODE_ERROR, `Invalid number byte data size.`);
    }
    return [(0, import_math13.toNumber)(bytes), offset + this.length];
  }
};

// src/coders/v1/raw-slice.ts
var import_errors21 = require("@fuel-ts/errors");
var import_math14 = require("@fuel-ts/math");
var RawSliceCoder2 = class extends Coder {
  constructor() {
    super("raw untyped slice", "raw untyped slice", WORD_SIZE);
  }
  encode(_value) {
    throw new import_errors21.FuelError(import_errors21.ErrorCode.ENCODE_ERROR, `Raw slice encode unsupported in v1`);
  }
  decode(data, offset) {
    if (data.length < this.encodedLength) {
      throw new import_errors21.FuelError(import_errors21.ErrorCode.DECODE_ERROR, `Invalid raw slice data size.`);
    }
    const offsetAndLength = offset + WORD_SIZE;
    const lengthBytes = data.slice(offset, offsetAndLength);
    const length = (0, import_math14.bn)(new U64Coder().decode(lengthBytes, 0)[0]).toNumber();
    const dataBytes = data.slice(offsetAndLength, offsetAndLength + length);
    if (dataBytes.length !== length) {
      throw new import_errors21.FuelError(import_errors21.ErrorCode.DECODE_ERROR, `Invalid raw slice byte data size.`);
    }
    const internalCoder = new ArrayCoder(new NumberCoder2("u8"), length);
    const [decodedValue] = internalCoder.decode(dataBytes, 0);
    return [decodedValue, offsetAndLength + length];
  }
};

// src/coders/v1/std-string.ts
var import_errors22 = require("@fuel-ts/errors");
var import_math15 = require("@fuel-ts/math");
var import_ethers6 = require("ethers");
var StdStringCoder2 = class extends Coder {
  constructor() {
    super("struct", "struct String", WORD_SIZE);
  }
  encode(_value) {
    throw new import_errors22.FuelError(import_errors22.ErrorCode.ENCODE_ERROR, `StdString encode unsupported in v1`);
  }
  decode(data, offset) {
    if (data.length < this.encodedLength) {
      throw new import_errors22.FuelError(import_errors22.ErrorCode.DECODE_ERROR, `Invalid std string data size.`);
    }
    const offsetAndLength = offset + WORD_SIZE;
    const lengthBytes = data.slice(offset, offsetAndLength);
    const length = (0, import_math15.bn)(new U64Coder().decode(lengthBytes, 0)[0]).toNumber();
    const dataBytes = data.slice(offsetAndLength, offsetAndLength + length);
    if (dataBytes.length !== length) {
      throw new import_errors22.FuelError(import_errors22.ErrorCode.DECODE_ERROR, `Invalid std string byte data size.`);
    }
    return [(0, import_ethers6.toUtf8String)(dataBytes), offsetAndLength + length];
  }
};
__publicField(StdStringCoder2, "memorySize", 1);

// src/coders/v1/string.ts
var import_errors23 = require("@fuel-ts/errors");
var import_ethers7 = require("ethers");
var StringCoder2 = class extends Coder {
  constructor(length) {
    super("string", `str[${length}]`, length);
  }
  encode(value) {
    if (value.length !== this.encodedLength) {
      throw new import_errors23.FuelError(import_errors23.ErrorCode.ENCODE_ERROR, `Value length mismatch during encode.`);
    }
    return (0, import_ethers7.toUtf8Bytes)(value);
  }
  decode(data, offset) {
    if (data.length < this.encodedLength) {
      throw new import_errors23.FuelError(import_errors23.ErrorCode.DECODE_ERROR, `Invalid string data size.`);
    }
    const bytes = data.slice(offset, offset + this.encodedLength);
    if (bytes.length !== this.encodedLength) {
      throw new import_errors23.FuelError(import_errors23.ErrorCode.DECODE_ERROR, `Invalid string byte data size.`);
    }
    return [(0, import_ethers7.toUtf8String)(bytes), offset + this.encodedLength];
  }
};

// src/coders/v1/struct.ts
var import_errors24 = require("@fuel-ts/errors");
var StructCoder2 = class extends Coder {
  name;
  coders;
  constructor(name, coders) {
    const encodedLength = Object.values(coders).reduce(
      (acc, coder) => acc + coder.encodedLength,
      0
    );
    super("struct", `struct ${name}`, encodedLength);
    this.name = name;
    this.coders = coders;
  }
  encode(_value) {
    throw new import_errors24.FuelError(import_errors24.ErrorCode.ENCODE_ERROR, `Struct encode unsupported in v1`);
  }
  decode(data, offset) {
    if (data.length < this.encodedLength) {
      throw new import_errors24.FuelError(import_errors24.ErrorCode.DECODE_ERROR, `Invalid struct data size.`);
    }
    let newOffset = offset;
    const decodedValue = Object.keys(this.coders).reduce((obj, fieldName) => {
      const fieldCoder = this.coders[fieldName];
      let decoded;
      [decoded, newOffset] = fieldCoder.decode(data, newOffset);
      obj[fieldName] = decoded;
      return obj;
    }, {});
    return [decodedValue, newOffset];
  }
};

// src/coders/v1/tuple.ts
var import_errors25 = require("@fuel-ts/errors");
var TupleCoder2 = class extends Coder {
  coders;
  constructor(coders) {
    const encodedLength = coders.reduce((acc, coder) => acc + coder.encodedLength, 0);
    super("tuple", `(${coders.map((coder) => coder.type).join(", ")})`, encodedLength);
    this.coders = coders;
  }
  encode(value) {
    if (this.coders.length !== value.length) {
      throw new import_errors25.FuelError(import_errors25.ErrorCode.ENCODE_ERROR, `Types/values length mismatch.`);
    }
    throw new import_errors25.FuelError(import_errors25.ErrorCode.ENCODE_ERROR, `Tuple encode unsupported in v1`);
  }
  decode(data, offset) {
    if (data.length < this.encodedLength) {
      throw new import_errors25.FuelError(import_errors25.ErrorCode.DECODE_ERROR, `Invalid tuple data size.`);
    }
    let newOffset = offset;
    const decodedValue = this.coders.map((coder) => {
      let decoded;
      [decoded, newOffset] = coder.decode(data, newOffset);
      return decoded;
    });
    return [decodedValue, newOffset];
  }
};

// src/coders/v1/vec.ts
var import_errors26 = require("@fuel-ts/errors");
var import_math16 = require("@fuel-ts/math");
var VecCoder2 = class extends Coder {
  coder;
  constructor(coder) {
    super("struct", `struct Vec`, coder.encodedLength + WORD_SIZE);
    this.coder = coder;
  }
  encode(_value) {
    throw new import_errors26.FuelError(import_errors26.ErrorCode.ENCODE_ERROR, `Vec encode unsupported in v1`);
  }
  decode(data, offset) {
    if (data.length < this.encodedLength || data.length > MAX_BYTES) {
      throw new import_errors26.FuelError(import_errors26.ErrorCode.DECODE_ERROR, `Invalid vec data size.`);
    }
    const offsetAndLength = offset + WORD_SIZE;
    const lengthBytes = data.slice(offset, offsetAndLength);
    const length = (0, import_math16.bn)(new U64Coder().decode(lengthBytes, 0)[0]).toNumber();
    const dataLength = length * this.coder.encodedLength;
    const dataBytes = data.slice(offsetAndLength, offsetAndLength + dataLength);
    if (dataBytes.length !== dataLength) {
      throw new import_errors26.FuelError(import_errors26.ErrorCode.DECODE_ERROR, `Invalid vec byte data size.`);
    }
    return [
      chunkByLength(dataBytes, this.coder.encodedLength).map(
        (chunk) => this.coder.decode(chunk, 0)[0]
      ),
      offsetAndLength + dataLength
    ];
  }
};

// src/resolved-abi-type.ts
var import_errors27 = require("@fuel-ts/errors");
var ResolvedAbiType = class {
  abi;
  name;
  type;
  originalTypeArguments;
  components;
  constructor(abi, argument) {
    this.abi = abi;
    const type = findOrThrow(
      abi.types,
      (t) => t.typeId === argument.type,
      () => {
        throw new import_errors27.FuelError(
          import_errors27.ErrorCode.TYPE_NOT_FOUND,
          `Type does not exist in the provided abi: ${JSON.stringify({
            argument,
            abi: this.abi
          })}`
        );
      }
    );
    this.name = argument.name;
    this.type = type.type;
    this.originalTypeArguments = argument.typeArguments;
    this.components = ResolvedAbiType.getResolvedGenericComponents(
      abi,
      argument,
      type.components,
      type.typeParameters ?? ResolvedAbiType.getImplicitGenericTypeParameters(abi, type.components)
    );
  }
  static getResolvedGenericComponents(abi, arg, components, typeParameters) {
    if (components === null) {
      return null;
    }
    if (typeParameters === null || typeParameters.length === 0) {
      return components.map((c) => new ResolvedAbiType(abi, c));
    }
    const typeParametersAndArgsMap = typeParameters.reduce(
      (obj, typeParameter, typeParameterIndex) => {
        const o = { ...obj };
        o[typeParameter] = structuredClone(
          arg.typeArguments?.[typeParameterIndex]
        );
        return o;
      },
      {}
    );
    const resolvedComponents = this.resolveGenericArgTypes(
      abi,
      components,
      typeParametersAndArgsMap
    );
    return resolvedComponents.map((c) => new ResolvedAbiType(abi, c));
  }
  static resolveGenericArgTypes(abi, args, typeParametersAndArgsMap) {
    return args.map((arg) => {
      if (typeParametersAndArgsMap[arg.type] !== void 0) {
        return {
          ...typeParametersAndArgsMap[arg.type],
          name: arg.name
        };
      }
      if (arg.typeArguments) {
        return {
          ...structuredClone(arg),
          typeArguments: this.resolveGenericArgTypes(
            abi,
            arg.typeArguments,
            typeParametersAndArgsMap
          )
        };
      }
      const argType = findOrThrow(abi.types, (t) => t.typeId === arg.type);
      const implicitTypeParameters = this.getImplicitGenericTypeParameters(abi, argType.components);
      if (implicitTypeParameters && implicitTypeParameters.length > 0) {
        return {
          ...structuredClone(arg),
          typeArguments: implicitTypeParameters.map((itp) => typeParametersAndArgsMap[itp])
        };
      }
      return arg;
    });
  }
  static getImplicitGenericTypeParameters(abi, args, implicitGenericParametersParam) {
    if (!Array.isArray(args)) {
      return null;
    }
    const implicitGenericParameters = implicitGenericParametersParam ?? [];
    args.forEach((a) => {
      const argType = findOrThrow(abi.types, (t) => t.typeId === a.type);
      if (genericRegEx.test(argType.type)) {
        implicitGenericParameters.push(argType.typeId);
        return;
      }
      if (!Array.isArray(a.typeArguments)) {
        return;
      }
      this.getImplicitGenericTypeParameters(abi, a.typeArguments, implicitGenericParameters);
    });
    return implicitGenericParameters.length > 0 ? implicitGenericParameters : null;
  }
  getSignature() {
    const prefix = this.getArgSignaturePrefix();
    const content = this.getArgSignatureContent();
    return `${prefix}${content}`;
  }
  getArgSignaturePrefix() {
    const structMatch = structRegEx.test(this.type);
    if (structMatch) {
      return "s";
    }
    const arrayMatch = arrayRegEx.test(this.type);
    if (arrayMatch) {
      return "a";
    }
    const enumMatch = enumRegEx.test(this.type);
    if (enumMatch) {
      return "e";
    }
    return "";
  }
  getArgSignatureContent() {
    if (this.type === "raw untyped ptr") {
      return "rawptr";
    }
    if (this.type === "raw untyped slice") {
      return "rawslice";
    }
    const strMatch = stringRegEx.exec(this.type)?.groups;
    if (strMatch) {
      return `str[${strMatch.length}]`;
    }
    if (this.components === null) {
      return this.type;
    }
    const arrayMatch = arrayRegEx.exec(this.type)?.groups;
    if (arrayMatch) {
      return `[${this.components[0].getSignature()};${arrayMatch.length}]`;
    }
    const typeArgumentsSignature = this.originalTypeArguments !== null ? `<${this.originalTypeArguments.map((a) => new ResolvedAbiType(this.abi, a).getSignature()).join(",")}>` : "";
    const componentsSignature = `(${this.components.map((c) => c.getSignature()).join(",")})`;
    return `${typeArgumentsSignature}${componentsSignature}`;
  }
};

// src/abi-coder.ts
var AbiCoder = class {
  static getCoder(abi, argument, options = {
    isSmallBytes: false
  }) {
    const resolvedAbiType = new ResolvedAbiType(abi, argument);
    return AbiCoder.getCoderImpl(resolvedAbiType, options);
  }
  static encode(abi, argument, value, options) {
    return this.getCoder(abi, argument, options).encode(value);
  }
  static decode(abi, argument, data, offset, options) {
    return this.getCoder(abi, argument, options).decode(data, offset);
  }
  static getCoderImpl(resolvedAbiType, options = {
    isSmallBytes: false
  }) {
    const { version } = options;
    switch (resolvedAbiType.type) {
      case "u8":
      case "u16":
      case "u32":
        return version ? new NumberCoder2(resolvedAbiType.type) : new NumberCoder(resolvedAbiType.type, options);
      case "u64":
      case "raw untyped ptr":
        return new U64Coder();
      case "raw untyped slice":
        return version ? new RawSliceCoder2() : new RawSliceCoder();
      case "bool":
        return version ? new BooleanCoder2() : new BooleanCoder(options);
      case "b256":
        return new B256Coder();
      case "struct B512":
        return new B512Coder();
      case BYTES_CODER_TYPE:
        return version ? new ByteCoder2() : new ByteCoder();
      case STD_STRING_CODER_TYPE:
        return version ? new StdStringCoder2() : new StdStringCoder();
      default:
        break;
    }
    const stringMatch = stringRegEx.exec(resolvedAbiType.type)?.groups;
    if (stringMatch) {
      const length = parseInt(stringMatch.length, 10);
      return version ? new StringCoder2(length) : new StringCoder(length);
    }
    const components = resolvedAbiType.components;
    const arrayMatch = arrayRegEx.exec(resolvedAbiType.type)?.groups;
    if (arrayMatch) {
      const length = parseInt(arrayMatch.length, 10);
      const arg = components[0];
      if (!arg) {
        throw new import_errors28.FuelError(
          import_errors28.ErrorCode.INVALID_COMPONENT,
          `The provided Array type is missing an item of 'component'.`
        );
      }
      const arrayElementCoder = AbiCoder.getCoderImpl(arg, { version, isSmallBytes: true });
      return new ArrayCoder(arrayElementCoder, length);
    }
    if (resolvedAbiType.type === VEC_CODER_TYPE) {
      const arg = findOrThrow(components, (c) => c.name === "buf").originalTypeArguments?.[0];
      if (!arg) {
        throw new import_errors28.FuelError(
          import_errors28.ErrorCode.INVALID_COMPONENT,
          `The provided Vec type is missing the 'type argument'.`
        );
      }
      const argType = new ResolvedAbiType(resolvedAbiType.abi, arg);
      const itemCoder = AbiCoder.getCoderImpl(argType, { version, isSmallBytes: true });
      return version ? new VecCoder2(itemCoder) : new VecCoder(itemCoder);
    }
    const structMatch = structRegEx.exec(resolvedAbiType.type)?.groups;
    if (structMatch) {
      const coders = AbiCoder.getCoders(components, { version, isRightPadded: true });
      return version ? new StructCoder2(structMatch.name, coders) : new StructCoder(structMatch.name, coders);
    }
    const enumMatch = enumRegEx.exec(resolvedAbiType.type)?.groups;
    if (enumMatch) {
      const coders = AbiCoder.getCoders(components, { version });
      const isOptionEnum = resolvedAbiType.type === OPTION_CODER_TYPE;
      if (isOptionEnum) {
        return new OptionCoder(enumMatch.name, coders);
      }
      return version ? new EnumCoder2(enumMatch.name, coders) : new EnumCoder(enumMatch.name, coders);
    }
    const tupleMatch = tupleRegEx.exec(resolvedAbiType.type)?.groups;
    if (tupleMatch) {
      const coders = components.map(
        (component) => AbiCoder.getCoderImpl(component, { version, isRightPadded: true })
      );
      return version ? new TupleCoder2(coders) : new TupleCoder(coders);
    }
    if (resolvedAbiType.type === "str") {
      throw new import_errors28.FuelError(
        import_errors28.ErrorCode.INVALID_DATA,
        "String slices can not be decoded from logs. Convert the slice to `str[N]` with `__to_str_array`"
      );
    }
    throw new import_errors28.FuelError(
      import_errors28.ErrorCode.CODER_NOT_FOUND,
      `Coder not found: ${JSON.stringify(resolvedAbiType)}.`
    );
  }
  static getCoders(components, options) {
    return components.reduce((obj, component) => {
      const o = obj;
      o[component.name] = AbiCoder.getCoderImpl(component, options);
      return o;
    }, {});
  }
};

// src/function-fragment.ts
var import_crypto = require("@fuel-ts/crypto");
var import_errors29 = require("@fuel-ts/errors");
var import_math17 = require("@fuel-ts/math");
var import_ethers8 = require("ethers");
var FunctionFragment = class {
  signature;
  selector;
  name;
  jsonFn;
  attributes;
  isInputDataPointer;
  outputMetadata;
  jsonAbi;
  constructor(jsonAbi, name) {
    this.jsonAbi = jsonAbi;
    this.jsonFn = findOrThrow(this.jsonAbi.functions, (f) => f.name === name);
    this.name = name;
    this.signature = FunctionFragment.getSignature(this.jsonAbi, this.jsonFn);
    this.selector = FunctionFragment.getFunctionSelector(this.signature);
    this.isInputDataPointer = this.#isInputDataPointer();
    this.outputMetadata = {
      isHeapType: this.#isOutputDataHeap(),
      encodedLength: this.#getOutputEncodedLength()
    };
    this.attributes = this.jsonFn.attributes ?? [];
  }
  static getSignature(abi, fn) {
    const inputsSignatures = fn.inputs.map(
      (input) => new ResolvedAbiType(abi, input).getSignature()
    );
    return `${fn.name}(${inputsSignatures.join(",")})`;
  }
  static getFunctionSelector(functionSignature) {
    const hashedFunctionSignature = (0, import_ethers8.sha256)((0, import_crypto.bufferFromString)(functionSignature, "utf-8"));
    return (0, import_math17.bn)(hashedFunctionSignature.slice(0, 10)).toHex(8);
  }
  #isInputDataPointer() {
    const inputTypes = this.jsonFn.inputs.map(
      (i) => this.jsonAbi.types.find((t) => t.typeId === i.type)
    );
    return this.jsonFn.inputs.length > 1 || isPointerType(inputTypes[0]?.type || "");
  }
  #isOutputDataHeap() {
    const outputType = findOrThrow(this.jsonAbi.types, (t) => t.typeId === this.jsonFn.output.type);
    return isHeapType(outputType?.type || "");
  }
  #getOutputEncodedLength() {
    try {
      const heapCoder = AbiCoder.getCoder(this.jsonAbi, this.jsonFn.output);
      if (heapCoder instanceof VecCoder) {
        return heapCoder.coder.encodedLength;
      }
      if (heapCoder instanceof ByteCoder) {
        return ByteCoder.memorySize;
      }
      return heapCoder.encodedLength;
    } catch (e) {
      return 0;
    }
  }
  encodeArguments(values, offset = 0) {
    FunctionFragment.verifyArgsAndInputsAlign(values, this.jsonFn.inputs, this.jsonAbi);
    const shallowCopyValues = values.slice();
    const nonEmptyInputs = this.jsonFn.inputs.filter(
      (x) => findOrThrow(this.jsonAbi.types, (t) => t.typeId === x.type).type !== "()"
    );
    if (Array.isArray(values) && nonEmptyInputs.length !== values.length) {
      shallowCopyValues.length = this.jsonFn.inputs.length;
      shallowCopyValues.fill(void 0, values.length);
    }
    const coders = nonEmptyInputs.map(
      (t) => AbiCoder.getCoder(this.jsonAbi, t, {
        isRightPadded: nonEmptyInputs.length > 1
      })
    );
    const coder = new TupleCoder(coders);
    const results = coder.encode(shallowCopyValues);
    return unpackDynamicData(results, offset, results.byteLength);
  }
  static verifyArgsAndInputsAlign(args, inputs, abi) {
    if (args.length === inputs.length) {
      return;
    }
    const inputTypes = inputs.map((i) => findOrThrow(abi.types, (t) => t.typeId === i.type));
    const optionalInputs = inputTypes.filter(
      (x) => x.type === OPTION_CODER_TYPE || x.type === "()"
    );
    if (optionalInputs.length === inputTypes.length) {
      return;
    }
    if (inputTypes.length - optionalInputs.length === args.length) {
      return;
    }
    const errorMsg = `Mismatch between provided arguments and expected ABI inputs. Provided ${args.length} arguments, but expected ${inputs.length - optionalInputs.length} (excluding ${optionalInputs.length} optional inputs).`;
    throw new import_errors29.FuelError(import_errors29.ErrorCode.ABI_TYPES_AND_VALUES_MISMATCH, errorMsg);
  }
  decodeArguments(data) {
    const bytes = (0, import_ethers8.getBytesCopy)(data);
    const nonEmptyInputs = this.jsonFn.inputs.filter(
      (x) => findOrThrow(this.jsonAbi.types, (t) => t.typeId === x.type).type !== "()"
    );
    if (nonEmptyInputs.length === 0) {
      if (bytes.length === 0) {
        return void 0;
      }
      throw new import_errors29.FuelError(
        import_errors29.ErrorCode.DECODE_ERROR,
        `Types/values length mismatch during decode. ${JSON.stringify({
          count: {
            types: this.jsonFn.inputs.length,
            nonEmptyInputs: nonEmptyInputs.length,
            values: bytes.length
          },
          value: {
            args: this.jsonFn.inputs,
            nonEmptyInputs,
            values: bytes
          }
        })}`
      );
    }
    const result = nonEmptyInputs.reduce(
      (obj, input) => {
        const coder = AbiCoder.getCoder(this.jsonAbi, input);
        const [decodedValue, decodedValueByteSize] = coder.decode(bytes, obj.offset);
        return {
          decoded: [...obj.decoded, decodedValue],
          offset: obj.offset + decodedValueByteSize
        };
      },
      { decoded: [], offset: 0 }
    );
    return result.decoded;
  }
  decodeOutput(data) {
    const outputAbiType = findOrThrow(
      this.jsonAbi.types,
      (t) => t.typeId === this.jsonFn.output.type
    );
    if (outputAbiType.type === "()") {
      return [void 0, 0];
    }
    const bytes = (0, import_ethers8.getBytesCopy)(data);
    const coder = AbiCoder.getCoder(this.jsonAbi, this.jsonFn.output);
    return coder.decode(bytes, 0);
  }
};

// src/interface.ts
var Interface = class {
  functions;
  configurables;
  /*
    TODO: Refactor so that there's no need for externalLoggedTypes
  
    This is dedicated to external contracts added via `<base-invocation-scope.ts>.addContracts()` method.
    This is used to decode logs from contracts other than the main contract
    we're interacting with.
    */
  externalLoggedTypes;
  jsonAbi;
  constructor(jsonAbi) {
    this.jsonAbi = jsonAbi;
    this.externalLoggedTypes = {};
    this.functions = Object.fromEntries(
      this.jsonAbi.functions.map((x) => [x.name, new FunctionFragment(this.jsonAbi, x.name)])
    );
    this.configurables = Object.fromEntries(this.jsonAbi.configurables.map((x) => [x.name, x]));
  }
  /**
   * Returns function fragment for a dynamic input.
   * @param nameOrSignatureOrSelector - name (e.g. 'transfer'), signature (e.g. 'transfer(address,uint256)') or selector (e.g. '0x00000000a9059cbb') of the function fragment
   */
  getFunction(nameOrSignatureOrSelector) {
    const fn = Object.values(this.functions).find(
      (f) => f.name === nameOrSignatureOrSelector || f.signature === nameOrSignatureOrSelector || f.selector === nameOrSignatureOrSelector
    );
    if (fn !== void 0) {
      return fn;
    }
    throw new import_errors30.FuelError(
      import_errors30.ErrorCode.FUNCTION_NOT_FOUND,
      `function ${nameOrSignatureOrSelector} not found: ${JSON.stringify(fn)}.`
    );
  }
  decodeFunctionData(functionFragment, data) {
    const fragment = typeof functionFragment === "string" ? this.getFunction(functionFragment) : functionFragment;
    if (!fragment) {
      throw new import_errors30.FuelError(import_errors30.ErrorCode.FRAGMENT_NOT_FOUND, "Fragment not found.");
    }
    return fragment.decodeArguments(data);
  }
  encodeFunctionData(functionFragment, values, offset = 0) {
    const fragment = typeof functionFragment === "string" ? this.getFunction(functionFragment) : functionFragment;
    if (!fragment) {
      throw new import_errors30.FuelError(import_errors30.ErrorCode.FRAGMENT_NOT_FOUND, "Fragment not found.");
    }
    return fragment.encodeArguments(values, offset);
  }
  // Decode the result of a function call
  decodeFunctionResult(functionFragment, data) {
    const fragment = typeof functionFragment === "string" ? this.getFunction(functionFragment) : functionFragment;
    return fragment.decodeOutput(data);
  }
  decodeLog(data, logId, receiptId) {
    const isExternalLoggedType = this.externalLoggedTypes[receiptId];
    if (isExternalLoggedType) {
      const externalInterface = this.externalLoggedTypes[receiptId];
      return externalInterface.decodeLog(data, logId, receiptId);
    }
    const { loggedType } = findOrThrow(this.jsonAbi.loggedTypes, (type) => type.logId === logId);
    return AbiCoder.decode(this.jsonAbi, loggedType, (0, import_ethers9.getBytesCopy)(data), 0, {
      version: this.jsonAbi.encoding
    });
  }
  updateExternalLoggedTypes(id, loggedTypes) {
    this.externalLoggedTypes[id] = loggedTypes;
  }
  encodeConfigurable(name, value) {
    const configurable = findOrThrow(
      this.jsonAbi.configurables,
      (c) => c.name === name,
      () => {
        throw new import_errors30.FuelError(
          import_errors30.ErrorCode.CONFIGURABLE_NOT_FOUND,
          `A configurable with the '${name}' was not found in the ABI.`
        );
      }
    );
    return AbiCoder.encode(this.jsonAbi, configurable.configurableType, value, {
      isRightPadded: true
    });
  }
  getTypeById(typeId) {
    return findOrThrow(
      this.jsonAbi.types,
      (t) => t.typeId === typeId,
      () => {
        throw new import_errors30.FuelError(
          import_errors30.ErrorCode.TYPE_NOT_FOUND,
          `Type with typeId '${typeId}' doesn't exist in the ABI.`
        );
      }
    );
  }
};
// Annotate the CommonJS export names for ESM import in node:
0 && (module.exports = {
  ASSET_ID_LEN,
  ArrayCoder,
  B256Coder,
  B512Coder,
  BooleanCoder,
  CONTRACT_ID_LEN,
  Coder,
  EnumCoder,
  INPUT_COIN_FIXED_SIZE,
  Interface,
  NumberCoder,
  SCRIPT_FIXED_SIZE,
  StringCoder,
  StructCoder,
  TupleCoder,
  U64Coder,
  VecCoder,
  WORD_SIZE,
  calculateVmTxMemory
});
//# sourceMappingURL=index.js.map